{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Text Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Module for preprocessing the image input to CNN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(img,imageSize,dataAug=False):\n",
    "\n",
    "    if img is None:\n",
    "        img = np.zeros([imageSize[1],imageSize[2]])\n",
    "    \n",
    "    if dataAug:\n",
    "        stretch = (random.random()-0.5)\n",
    "        wStretched = max(int(img.shape[1] * (1 + stretch)), 1)\n",
    "        img = cv2.resize(img, (wStretched, img.shape[0]))\n",
    "\n",
    "    (wt,ht) = imageSize\n",
    "    (h,w)   = img.shape\n",
    "    fx = w/wt\n",
    "    fy = h/ht\n",
    "    f = max(fx,fy)\n",
    "    newSize = (max(min(wt, int(w / f)), 1), max(min(ht, int(h / f)), 1))\n",
    "    img = cv2.resize(img,newSize)\n",
    "\n",
    "    target = np.ones([ht, wt]) * 255\n",
    "    target[0:newSize[1], 0:newSize[0]]=img\n",
    "\n",
    "    img = cv2.transpose(target)\n",
    "    (m, s) = cv2.meanStdDev(img)\n",
    "\n",
    "    m = m[0][0]\n",
    "    s = s[0][0]\n",
    "    img = img - m\n",
    "    img = img / s if s>0 else img\n",
    "\n",
    "    return img\n",
    "\n",
    "# img = cv2.imread('data/test.png',cv2.IMREAD_GRAYSCALE)\n",
    "# cv2.imshow('image',img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# img = preprocess(img,(128, 32))\n",
    "# cv2.imshow('image',img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader - Functions required to fetch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "# from imagePreprocessing import preprocess\n",
    "\n",
    "class Sample:\n",
    "    # sample from the dataset\n",
    "    def __init__(self, gtText, filePath):\n",
    "        self.gtText = gtText\n",
    "        self.filePath = filePath\n",
    "\n",
    "class Batch:\n",
    "    # batch containing images and ground truth texts\n",
    "    def __init__(self, gtTexts, imgs):\n",
    "        self.imgs = np.stack(imgs, axis=0)\n",
    "        self.gtTexts = gtTexts\n",
    "\n",
    "class DataLoader:\n",
    "    # loads data which corresponds to IAM format, see: http://www.fki.inf.unibe.ch/databases/iam-handwriting-database\" \n",
    "\n",
    "    def __init__(self, filePath, batchSize, imgSize, maxTextLen):\n",
    "        \"loader for dataset at given location, preprocess images and text according to parameters\"\n",
    "\n",
    "        assert filePath[-1]=='/'\n",
    "\n",
    "        self.dataAugmentation = False\n",
    "        self.currIdx = 0\n",
    "        self.batchSize = batchSize\n",
    "        self.imgSize = imgSize\n",
    "        self.samples = []\n",
    "    \n",
    "        f=open(filePath+'words.txt')\n",
    "        chars = set()\n",
    "        bad_samples = []\n",
    "        bad_samples_reference = ['a01-117-05-02.png', 'r06-022-03-05.png']\n",
    "        for line in f:\n",
    "            # ignore comment line\n",
    "            if not line or line[0]=='#':\n",
    "                continue\n",
    "\n",
    "            lineSplit = line.strip().split(' ')\n",
    "            # assert len(lineSplit) >= 9\n",
    "\n",
    "            # filename: part1-part2-part3 --> part1/part1-part2/part1-part2-part3.png\n",
    "            fileNameSplit = lineSplit[0].split('-')\n",
    "            fileName = filePath + 'words/' + fileNameSplit[0] + '/' + fileNameSplit[0] + '-' + fileNameSplit[1] + '/' + lineSplit[0] + '.png'\n",
    "\n",
    "            # GT text are columns starting at 9\n",
    "            gtText = self.truncateLabel(' '.join(lineSplit[8:]), maxTextLen)\n",
    "            chars = chars.union(set(list(gtText)))\n",
    "\n",
    "            #  check if image is not empty\n",
    "            if not os.path.getsize(fileName):\n",
    "                bad_samples.append(lineSplit[0] + '.png')\n",
    "                continue\n",
    "\n",
    "            # put sample into list\n",
    "            self.samples.append(Sample(gtText, fileName))\n",
    "\n",
    "        # some images in the IAM dataset are known to be damaged, don't show warning for them\n",
    "        if set(bad_samples) != set(bad_samples_reference):\n",
    "            print(\"Warning, damaged images found:\", bad_samples)\n",
    "            print(\"Damaged images expected:\", bad_samples_reference)\n",
    "\n",
    "        # split into training and validation set: 95% - 5%\n",
    "        splitIdx = int(0.95 * len(self.samples))\n",
    "        self.trainSamples = self.samples[:splitIdx]\n",
    "        self.validationSamples = self.samples[splitIdx:]\n",
    "\n",
    "        # put words into lists\n",
    "        self.trainWords = [x.gtText for x in self.trainSamples]\n",
    "        self.validationWords = [x.gtText for x in self.validationSamples]\n",
    "\n",
    "        # number of randomly chosen samples per epoch for training \n",
    "        self.numTrainSamplesPerEpoch = 25000 \n",
    "\n",
    "        # start with train set\n",
    "        self.trainSet()\n",
    "\n",
    "        # list of all chars in dataset\n",
    "        self.charList = sorted(list(chars))\n",
    "\n",
    "\n",
    "    def truncateLabel(self, text, maxTextLen):\n",
    "        # ctc_loss can't compute loss if it cannot find a mapping between text label and input \n",
    "        # labels. Repeat letters cost double because of the blank symbol needing to be inserted.\n",
    "        # If a too-long label is provided, ctc_loss returns an infinite gradient\n",
    "        cost = 0\n",
    "        for i in range(len(text)):\n",
    "            if i != 0 and text[i] == text[i-1]:\n",
    "                cost += 2\n",
    "            else:\n",
    "                cost += 1\n",
    "            if cost > maxTextLen:\n",
    "                return text[:i]\n",
    "        return text\n",
    "\n",
    "    def trainSet(self):\n",
    "        # switch to randomly chosen subset of training set\n",
    "        self.dataAugmentation = True\n",
    "        self.currIdx = 0\n",
    "        random.shuffle(self.trainSamples)\n",
    "        self.samples = self.trainSamples[:self.numTrainSamplesPerEpoch]\n",
    "\n",
    "\n",
    "    def validationSet(self):\n",
    "        # switch to validation set\n",
    "        self.dataAugmentation = False\n",
    "        self.currIdx = 0\n",
    "        self.samples = self.validationSamples\n",
    "\n",
    "\n",
    "    def getIteratorInfo(self):\n",
    "        # current batch index and overall number of batches\n",
    "        return (self.currIdx // self.batchSize + 1, len(self.samples) // self.batchSize)\n",
    "\n",
    "\n",
    "    def hasNext(self):\n",
    "        # \"iterator\"\n",
    "        return self.currIdx + self.batchSize <= len(self.samples)\n",
    "\n",
    "    \n",
    "    def getNext(self):\n",
    "        # iterator\n",
    "        batchRange = range(self.currIdx, self.currIdx + self.batchSize)\n",
    "        gtTexts = [self.samples[i].gtText for i in batchRange]\n",
    "        imgs = [preprocess(cv2.imread(self.samples[i].filePath, cv2.IMREAD_GRAYSCALE), self.imgSize, self.dataAugmentation) for i in batchRange]\n",
    "        self.currIdx += self.batchSize\n",
    "        return Batch(gtTexts, imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input to neural network is a grayscale image of size 128*32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN layers maps the image to feature sequence \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN layers with 256 units "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CTC layer either calculates the loss value given the matrix and the ground-truth text (when training), or it decodes the matrix to the final text with best path decoding or beam search decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class DecoderType:\n",
    "    BestPath = 0\n",
    "    BeamSearch = 1\n",
    "    WordBeamSearch = 2\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    batchSize = 50\n",
    "    imageSize = (128, 32)\n",
    "    maxTextLen = 32\n",
    "\n",
    "    def __init__(self, charList, decoderType=DecoderType.BestPath, mustRestore=False, dump=False):\n",
    "        self.dump = dump\n",
    "        self.charList = charList\n",
    "        self.decoderType = decoderType\n",
    "        self.mustRestore = mustRestore\n",
    "        self.snapID = 0\n",
    "\n",
    "        self.is_train = tf.placeholder(tf.bool, name='is_train')\n",
    "\n",
    "        self.inputImg = tf.placeholder(tf.float32, shape=(\n",
    "            None, Model.imageSize[0], Model.imageSize[1]))\n",
    "\n",
    "        self.setupCNN()\n",
    "        self.setupRNN()\n",
    "        self.setupCTC()\n",
    "\n",
    "        self.batchesTrained = 0\n",
    "        self.learningRate = tf.placeholder(tf.float32, shape=[])\n",
    "        self.update_op = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(self.update_op):\n",
    "            self.optimizer = tf.train.RMSPropOptimizer(\n",
    "                self.learningRate).minimize(self.loss)\n",
    "\n",
    "        (self.sess, self.saver) = self.setupTF()\n",
    "\n",
    "    def setupCNN(self):\n",
    "        # create cnn layer and return output of these layers\n",
    "        cnnIn4d = tf.expand_dims(input=self.inputImg, axis=3)\n",
    "\n",
    "        # list of parameters for the layers\n",
    "        kernelVals = [5, 5, 3, 3, 3]\n",
    "        featureVals = [1, 32, 64, 128, 128, 256]\n",
    "        strideVals = poolVals = [(2, 2), (2, 2), (1, 2), (1, 2), (1, 2)]\n",
    "        numLayers = len(strideVals)\n",
    "        # CNN layer\n",
    "        pool = cnnIn4d\n",
    "\n",
    "        for i in range(numLayers):\n",
    "            kernel = tf.Variable(tf.truncated_normal(\n",
    "                [kernelVals[i], kernelVals[i], featureVals[i], featureVals[i + 1]], stddev=0.1))\n",
    "            conv = tf.nn.conv2d(\n",
    "                pool, kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            conv_norm = tf.layers.batch_normalization(\n",
    "                conv, training=self.is_train)\n",
    "            relu = tf.nn.relu(conv_norm)\n",
    "            pool = tf.nn.max_pool(relu, (1, poolVals[i][0], poolVals[i][1], 1), (\n",
    "                1, strideVals[i][0], strideVals[i][1], 1), 'VALID')\n",
    "\n",
    "        self.cnnOut4d = pool\n",
    "\n",
    "    def setupRNN(self):\n",
    "        # create rnn layers and return output of these layers\n",
    "        rnnIn3d = tf.squeeze(self.cnnOut4d, axis=[2])\n",
    "\n",
    "        numHidden = 256\n",
    "        cell = [tf.contrib.rnn.LSTMCell(\n",
    "            num_units=numHidden, state_is_tuple=True) for _ in range(2)]  # 2 layers\n",
    "\n",
    "        stacked = tf.contrib.rnn.MultiRNNCell(cell, state_is_tuple=True)\n",
    "\n",
    "        # bidirectional rnn\n",
    "        ((fw, bw), _) = tf.nn.bidirectional_dynamic_rnn(\n",
    "            cell_fw=stacked, cell_bw=stacked, inputs=rnnIn3d, dtype=rnnIn3d.dtype)\n",
    "\n",
    "        concat = tf.expand_dims(tf.concat([fw, bw], 2), 2)\n",
    "\n",
    "        kernel = tf.Variable(tf.truncated_normal(\n",
    "            [1, 1, numHidden * 2, len(self.charList) + 1], stddev=0.1))\n",
    "\n",
    "        self.rnnOut3d = tf.squeeze(tf.nn.atrous_conv2d(\n",
    "            value=concat, filters=kernel, rate=1, padding='SAME'), axis=[2])\n",
    "\n",
    "    def setupCTC(self):\n",
    "        # calculate loss, decode the word and return\n",
    "        self.ctcIn3d = tf.transpose(self.rnnOut3d, [1, 0, 2])\n",
    "        self.gtText = tf.SparseTensor(tf.placeholder(tf.int64, shape=[None, 2]), tf.placeholder(\n",
    "            tf.int32, shape=[None]), tf.placeholder(tf.int64, shape=[2]))\n",
    "\n",
    "        # loss for batch\n",
    "        self.seqLen = tf.placeholder(tf.int32, [None])\n",
    "        self.loss = tf.reduce_mean(tf.nn.ctc_loss(labels=self.gtText, inputs=self.ctcIn3d, sequence_length=self.seqLen, ctc_merge_repeated=True))\n",
    "\n",
    "        # loss for each element\n",
    "        self.savedCtcInput = tf.placeholder(\n",
    "            tf.float32, shape=[Model.maxTextLen, None, len(self.charList)+1])\n",
    "        self.lossPerElement = tf.nn.ctc_loss(\n",
    "            labels=self.gtText, inputs=self.savedCtcInput, sequence_length=self.seqLen, ctc_merge_repeated=True)\n",
    "\n",
    "        # decoder\n",
    "        if self.decoderType == DecoderType.BestPath:\n",
    "            self.decoder = tf.nn.ctc_greedy_decoder(\n",
    "                inputs=self.ctcIn3d, sequence_length=self.seqLen)\n",
    "        elif self.decoderType == DecoderType.BeamSearch:\n",
    "            self.decoder = tf.nn.ctc_beam_search_decoder(\n",
    "                inputs=self.ctcIn3d, sequence_length=self.seqLen, beam_width=50, merge_repeated=False)\n",
    "        elif self.decoderType == DecoderType.WordBeamSearch:\n",
    "            word_beam_search_module = tf.load_op_library('TFWordBeamSearch.so')\n",
    "\n",
    "            # prepare information about language (dictionary, characters in dataset, characters forming words)\n",
    "            chars = str().join(self.charList)\n",
    "            wordChars = open('model/wordCharList.txt').read().splitlines()[0]\n",
    "            corpus = open('data/corpus.txt').read()\n",
    "\n",
    "            # decode using the \"Words\" mode of word beam search\n",
    "            self.decoder = word_beam_search_module.word_beam_search(tf.nn.softmax(\n",
    "                self.ctcIn3d, dim=2), 50, 'Words', 0.0, corpus.encode('utf8'), chars.encode('utf8'), wordChars.encode('utf8'))\n",
    "\n",
    "    def setupTF(self):\n",
    "        # print('Python: '+sys.version)\n",
    "        # print('Tensorflow: '+tf.__version__)\n",
    "        # TF session\n",
    "        sess = tf.Session()  \n",
    "        saver = tf.train.Saver(max_to_keep=1,reshape=True)  # saver saves model to file\n",
    "        modelDir = 'model/'     \n",
    "        latestSnapshot = tf.train.latest_checkpoint(modelDir)  # is there a saved model?\n",
    "\n",
    "        # if model must be restored (for inference), there must be a snapshot\n",
    "        if self.mustRestore and not latestSnapshot:\n",
    "            raise Exception('No saved model found in: ' + modelDir)\n",
    "\n",
    "        # load saved model if available\n",
    "        if latestSnapshot:\n",
    "            print('Init with stored values from ' + latestSnapshot)\n",
    "            saver.restore(sess, latestSnapshot)\n",
    "        else:\n",
    "            print('Init with new values')\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        return (sess, saver)\n",
    "\n",
    "    def toSparse(self, texts):\n",
    "    \n",
    "        indices = []\n",
    "        values = []\n",
    "        shape = [len(texts), 0] # last entry must be max(labelList[i])\n",
    "\n",
    "        # go over all texts\n",
    "        for (batchElement, text) in enumerate(texts):\n",
    "            # convert to string of label (i.e. class-ids)\n",
    "            labelStr = [self.charList.index(c) for c in text]\n",
    "            # sparse tensor must have size of max. label-string\n",
    "            if len(labelStr) > shape[1]:\n",
    "                shape[1] = len(labelStr)\n",
    "            # put each label into sparse tensor\n",
    "            for (i, label) in enumerate(labelStr):\n",
    "                indices.append([batchElement, i])\n",
    "                values.append(label)\n",
    "\n",
    "        return (indices, values, shape)\n",
    "\n",
    "    def decoderOutputToText(self, ctcOutput, batchSize):\n",
    "    \n",
    "        # contains string of labels for each batch element\n",
    "        encodedLabelStrs = [[] for i in range(batchSize)]\n",
    "\n",
    "        # word beam search: label strings terminated by blank\n",
    "        if self.decoderType == DecoderType.WordBeamSearch:\n",
    "            blank = len(self.charList)\n",
    "            for b in range(batchSize):\n",
    "                for label in ctcOutput[b]:\n",
    "                    if label == blank:\n",
    "                        break\n",
    "                    encodedLabelStrs[b].append(label)\n",
    "\n",
    "        # TF decoders: label strings are contained in sparse tensor\n",
    "        else:\n",
    "            # ctc returns tuple, first element is SparseTensor\n",
    "            decoded = ctcOutput[0][0]\n",
    "\n",
    "        # go over all indices and save mapping: batch -> values\n",
    "        idxDict = {b: [] for b in range(batchSize)}\n",
    "        for (idx, idx2d) in enumerate(decoded.indices):\n",
    "            label = decoded.values[idx]\n",
    "            batchElement = idx2d[0]  # index according to [b,t]\n",
    "            encodedLabelStrs[batchElement].append(label)\n",
    "\n",
    "        # map labels to chars for all batch elements\n",
    "        return [str().join([self.charList[c] for c in labelStr]) for labelStr in encodedLabelStrs]\n",
    "\n",
    "    def trainBatch(self, batch):\n",
    "        # feed a batch into the NN to train it\n",
    "        numBatchElements = len(batch.imgs)\n",
    "        sparse = self.toSparse(batch.gtTexts)\n",
    "        rate = 0.01 if self.batchesTrained < 10 else (0.001 if self.batchesTrained < 10000 else 0.0001)  # decay learning rate\n",
    "        evalList = [self.optimizer, self.loss]\n",
    "        feedDict = {self.inputImg: batch.imgs, self.gtText: sparse, self.seqLen: [Model.maxTextLen] * numBatchElements, self.learningRate: rate, self.is_train: True}\n",
    "        (_, lossVal) = self.sess.run(evalList, feedDict)\n",
    "        self.batchesTrained += 1\n",
    "        return lossVal\n",
    "\n",
    "    def dumpNNOutput(self, rnnOutput):\n",
    "        # dump the output of the NN to CSV file(s)\n",
    "        dumpDir = 'dump/'\n",
    "        if not os.path.isdir(dumpDir):\n",
    "            os.mkdir(dumpDir)\n",
    "\n",
    "        # iterate over all batch elements and create a CSV file for each one\n",
    "        maxT, maxB, maxC = rnnOutput.shape\n",
    "        for b in range(maxB):\n",
    "            csv = ''\n",
    "            for t in range(maxT):\n",
    "                for c in range(maxC):\n",
    "                    csv += str(rnnOutput[t, b, c]) + ';'\n",
    "                    csv += '\\n'\n",
    "                    fn = dumpDir + 'rnnOutput_'+str(b)+'.csv'\n",
    "                    print('Write dump of NN to file: ' + fn)\n",
    "                    with open(fn, 'w') as f:\n",
    "                        f.write(csv)\n",
    "\n",
    "    def inferBatch(self, batch, calcProbability=False, probabilityOfGT=False):\n",
    "        # feed a batch into the NN to recognize the texts\n",
    "\n",
    "        # decode, optionally save RNN output\n",
    "        numBatchElements = len(batch.imgs)\n",
    "        evalRnnOutput = self.dump or calcProbability\n",
    "        evalList = [self.decoder] + ([self.ctcIn3dTBC] if evalRnnOutput else [])\n",
    "        feedDict = {self.inputImg: batch.imgs, self.seqLen: [\n",
    "        Model.maxTextLen] * numBatchElements, self.is_train: False}\n",
    "        evalRes = self.sess.run(evalList, feedDict)\n",
    "        decoded = evalRes[0]\n",
    "        texts = self.decoderOutputToText(decoded, numBatchElements)\n",
    "\n",
    "        # feed RNN output and recognized text into CTC loss to compute labeling probability\n",
    "        probs = None\n",
    "        if calcProbability:\n",
    "            sparse = self.toSparse(batch.gtTexts) if probabilityOfGT else self.toSparse(texts)\n",
    "            ctcInput = evalRes[1]\n",
    "            evalList = self.lossPerElement\n",
    "            feedDict = {self.savedCtcInput: ctcInput, self.gtText: sparse, self.seqLen: [Model.maxTextLen] * numBatchElements, self.is_train: False}\n",
    "            lossVals = self.sess.run(evalList, feedDict)\n",
    "            probs = np.exp(-lossVals)\n",
    "\n",
    "        # dump the output of the NN to CSV file(s)\n",
    "        if self.dump:\n",
    "            self.dumpNNOutput(evalRes[1])\n",
    "\n",
    "        return (texts, probs)\n",
    "\n",
    "    def save(self):\n",
    "        # save model to file\n",
    "        self.snapID += 1\n",
    "        self.saver.save(self.sess, 'model/snapshot', global_step=self.snapID)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# from DataProcessing import Batch\n",
    "# from model import Model, DecoderType\n",
    "# from imagePreprocessing import preprocess\n",
    "\n",
    "\n",
    "class Constants:\n",
    "    #filenames and paths to data\n",
    "    fnCharList = 'model/charList.txt'\n",
    "    fnAnalyze = 'data/analyze.png'\n",
    "    fnPixelRelevance = 'data/pixelRelevance.npy'\n",
    "    fnTranslationInvariance = 'data/translationInvariance.npy'\n",
    "    fnTranslationInvarianceTexts = 'data/translationInvarianceTexts.pickle'\n",
    "    gtText = 'are'\n",
    "    distribution = 'histogram' # 'histogram' or 'uniform'\n",
    "\n",
    "\n",
    "def odds(val):\n",
    "    return val / (1 - val)\n",
    "\n",
    "\n",
    "def weightOfEvidence(origProb, margProb):\n",
    "    return math.log2(odds(origProb)) - math.log2(odds(margProb))\n",
    "\n",
    "def analyzePixelRelevance():\n",
    "    model = Model(open(Constants.fnCharList).read(), DecoderType.BestPath, mustRestore=True)\n",
    "    \n",
    "    # read image and specify ground-truth text\n",
    "    img = cv2.imread(Constants.fnAnalyze, cv2.IMREAD_GRAYSCALE)\n",
    "    w: object\n",
    "    (w, h) = img.shape\n",
    "    assert Model.imgSize[1] == w\n",
    "\n",
    "    # compute probability of gt text in original image\n",
    "    batch = Batch([Constants.gtText], [preprocess(img, Model.imgSize)])\n",
    "    (_, probs) = model.inferBatch(batch, calcProbability=True, probabilityOfGT=True)\n",
    "    origProb = probs[0]\n",
    "\n",
    "    grayValues = [0, 63, 127, 191, 255]\n",
    "    if Constants.distribution == 'histogram':\n",
    "        bins = [0, 31, 95, 159, 223, 255]\n",
    "        (hist, _) = np.histogram(img, bins=bins)\n",
    "        pixelProb = hist / sum(hist)\n",
    "    elif Constants.distribution == 'uniform':\n",
    "        pixelProb = [1.0 / len(grayValues) for _ in grayValues]\n",
    "    else:\n",
    "        raise Exception('unknown value for Constants.distribution')\n",
    "\n",
    "    # iterate over all pixels in image\n",
    "    pixelRelevance = np.zeros(img.shape, np.float32)\n",
    "    for x in range(w):\n",
    "        for y in range(h):\n",
    "\n",
    "            # try a subset of possible grayvalues of pixel (x,y)\n",
    "            imgsMarginalized = []\n",
    "            for g in grayValues:\n",
    "                imgChanged = copy.deepcopy(img)\n",
    "                imgChanged[x, y] = g\n",
    "                imgsMarginalized.append(preprocess(imgChanged, Model.imgSize))\n",
    "\n",
    "            # put them all into one batch\n",
    "            batch = Batch([Constants.gtText]*len(imgsMarginalized), imgsMarginalized)\n",
    "\n",
    "            # compute probabilities\n",
    "            (_, probs) = model.inferBatch(batch, calcProbability=True, probabilityOfGT=True)\n",
    "\n",
    "            # marginalize over pixel value (assume uniform distribution)\n",
    "            margProb = sum([probs[i] * pixelProb[i] for i in range(len(grayValues))])\n",
    "\n",
    "            pixelRelevance[x, y] = weightOfEvidence(origProb, margProb)\n",
    "\n",
    "            print(x, y, pixelRelevance[x, y], origProb, margProb)\n",
    "\n",
    "    np.save(Constants.fnPixelRelevance, pixelRelevance)\n",
    "\n",
    "def analyzeTranslationInvariance():\n",
    "    # setup model\n",
    "    model = Model(open(Constants.fnCharList).read(), DecoderType.BestPath, mustRestore=True)\n",
    "\n",
    "    # read image and specify ground-truth text\n",
    "    img = cv2.imread(Constants.fnAnalyze, cv2.IMREAD_GRAYSCALE)\n",
    "    (w, h) = img.shape\n",
    "    assert Model.imgSize[1] == w\n",
    "    \n",
    "    imgList = []\n",
    "    for dy in range(Model.imgSize[0]-h+1):\n",
    "        targetImg = np.ones((Model.imgSize[1], Model.imgSize[0])) * 255\n",
    "        targetImg[:,dy:h+dy] = img\n",
    "        imgList.append(preprocess(targetImg, Model.imgSize))\n",
    "\n",
    "    # put images and gt texts into batch\n",
    "    batch = Batch([Constants.gtText]*len(imgList), imgList)\n",
    "\n",
    "    # compute probabilities\n",
    "    (texts, probs) = model.inferBatch(batch, calcProbability=True, probabilityOfGT=True)\n",
    "\n",
    "    # save results to file\n",
    "    f = open(Constants.fnTranslationInvarianceTexts, 'wb')\n",
    "    pickle.dump(texts, f)\n",
    "    f.close()\n",
    "    np.save(Constants.fnTranslationInvariance, probs)\n",
    "\n",
    "\n",
    "def showResults():\n",
    "    # 1. pixel relevance\n",
    "    pixelRelevance = np.load(Constants.fnPixelRelevance)\n",
    "    plt.figure('Pixel relevance')\n",
    "\n",
    "    plt.imshow(pixelRelevance, cmap=plt.cm.jet, vmin=-0.25, vmax=0.25)\n",
    "    plt.colorbar()\n",
    "\n",
    "    img = cv2.imread(Constants.fnAnalyze, cv2.IMREAD_GRAYSCALE)\n",
    "    plt.imshow(img, cmap=plt.cm.gray, alpha=.4)\n",
    "\n",
    "\n",
    "    # 2. translation invariance\n",
    "    probs = np.load(Constants.fnTranslationInvariance)\n",
    "    f = open(Constants.fnTranslationInvarianceTexts, 'rb')\n",
    "    texts = pickle.load(f)\n",
    "    texts = ['%d:'%i + texts[i] for i in range(len(texts))]\n",
    "    f.close()\n",
    "\n",
    "    plt.figure('Translation invariance')\n",
    "\n",
    "    plt.plot(probs, 'o-')\n",
    "    plt.xticks(np.arange(len(texts)), texts, rotation='vertical')\n",
    "    plt.xlabel('horizontal translation and best path')\n",
    "    plt.ylabel('text probability of \"%s\"'%Constants.gtText)\n",
    "\n",
    "    # show both plots\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if len(sys.argv)>1:\n",
    "        if sys.argv[1]=='--relevance':\n",
    "            print('Analyze pixel relevance')\n",
    "            analyzePixelRelevance()\n",
    "        elif sys.argv[1]=='--invariance':\n",
    "            print('Analyze translation invariance')\n",
    "            analyzeTranslationInvariance()\n",
    "    else:\n",
    "        print('Show results')\n",
    "        showResults()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--train] [--validate] [--beamsearch]\n",
      "                             [--wordbeamsearch] [--dump]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1001/jupyter/kernel-58cd57e8-ea3d-4537-a485-66fffea599a1.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# smeenapadnekar\n",
    "# 28/07/2019\n",
    "\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os \n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "import editdistance\n",
    "# from imagePreprocessing import preprocess\n",
    "# from model import Model, DecoderType\n",
    "# from DataProcessing import DataLoader, Batch\n",
    "\n",
    "# File path \n",
    "class FilePath:\n",
    "    input = 'data/test.png'\n",
    "    charList = 'model/charList.txt'\n",
    "    accuracy = 'model/accuracy.txt'\n",
    "    train = 'data/'\n",
    "    corpus = 'data/corpus.txt'\n",
    "\n",
    "def train(model, loader):\n",
    "    epoc = 0\n",
    "    bestCharErrorRate = float('inf')\n",
    "    noImprovement = 0\n",
    "    earlyStopping = 5\n",
    "\n",
    "    while True:\n",
    "        epoc += 1\n",
    "        print('Epoc',epoc)\n",
    "        loader.trainSet()\n",
    "        print('Training Neural Network')\n",
    "        while loader.hasNext():\n",
    "            iterInfo = loader.getIteratorInfo()\n",
    "            Batch = loader.getNext()\n",
    "            loss = model.trainBatch(Batch)\n",
    "            print('Batch : ',iterInfo[0],'/',iterInfo[1],' Loss =',loss)\n",
    "        \n",
    "        print('Validate')\n",
    "        charErrorRate = validate(model,loader)\n",
    "\n",
    "        if charErrorRate < bestCharErrorRate:\n",
    "            print('Increase in accuracy. Saving Model')\n",
    "            bestCharErrorRate = charErrorRate\n",
    "            noImprovement = 0\n",
    "            model.save()\n",
    "            open(FilePath.accuracy,'w').write('Validation Character error rate of the saved model%f%%'%(bestCharErrorRate*100))\n",
    "        else:\n",
    "            print('No increase in Accuracy')\n",
    "            noImprovement +=1\n",
    "        \n",
    "        # stopping if no improving in acc after 5 epoc\n",
    "        if noImprovement>=earlyStopping:\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def validate(model, loader):\n",
    "    loader.validationSet()\n",
    "    numCharErr = 0\n",
    "    numCharTotal = 0\n",
    "    numWordOK = 0\n",
    "    numWordTotal = 0\n",
    "    while loader.hasNext():\n",
    "        iterInfo = loader.getIteratorInfo()\n",
    "        print('Batch:', iterInfo[0],'/', iterInfo[1])\n",
    "        batch = loader.getNext()\n",
    "        (recognized,_) = model.inferBatch(batch)\n",
    "\n",
    "        for i in range(len(recognized)):\n",
    "            numWordOK += 1 if batch.gtText[i] == recognized[i] else 0 \n",
    "            numWordTotal +=1\n",
    "            dist = editdistance.eval(recognized[i],batch.gtText[i])\n",
    "            numCharErr += dist\n",
    "            numCharTotal += len(batch.gtText[i])\n",
    "            print('[OK]' if dist==0 else '[ERR:%d]' % dist,'\"' + batch.gtTexts[i] + '\"', '->', '\"' + recognized[i] + '\"')\n",
    "\n",
    "    # print validation result\n",
    "    charErrorRate = numCharErr/numCharTotal if numCharTotal !=0 else 0\n",
    "    wordAccuracy = numWordOK/numWordTotal if numWordTotal !=0 else 0\n",
    "    print('Character error rate: %f%%. Word accuracy: %f%%.' % (charErrorRate*100.0, wordAccuracy*100.0))\n",
    "    return charErrorRate\n",
    "\n",
    "def recognize(model,InImage):\n",
    "    img = preprocess(cv2.imread(InImage,cv2.IMREAD_GRAYSCALE),Model.imageSize)\n",
    "    batch = Batch(None,[img])\n",
    "    (recognized,probability) = model.inferBatch(batch, True)\n",
    "    print('Recognized:', '\"' + recognized[0] + '\"')\n",
    "    print('Probability:', probability[0])\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--train', help='train the Neural network', action='store_true')\n",
    "    parser.add_argument('--validate', help='test the Neural network', action='store_true')\n",
    "    parser.add_argument('--beamsearch', help='use beam search instead of best path decoding', action='store_true')\n",
    "    parser.add_argument('--wordbeamsearch', help='use word beam search instead of best path decoding', action='store_true')\n",
    "    parser.add_argument('--dump', help='store the NN weights', action='store_true')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    decoderType = DecoderType.BestPath\n",
    "    if args.beamsearch:\n",
    "        decoderType = DecoderType.BeamSearch\n",
    "    elif args.wordbeamsearch:\n",
    "        decoderType = DecoderType.WordBeamSearch\n",
    "\n",
    "    if args.train or args.validate :\n",
    "        # load training data\n",
    "        # execute training and validation\n",
    "        loader = DataLoader(FilePath.train,Model.batchSize,Model.imageSize,Model.maxTextLen)\n",
    "        open(FilePath.charList, 'w').write(str().join(loader.charList))\n",
    "        open(FilePath.corpus,'w').write(str(' ').join(loader.trainWords + loader.validationWords))\n",
    "\n",
    "        if args.train:\n",
    "            # training\n",
    "            model = Model(loader.charList,decoderType)\n",
    "            train(model, loader)\n",
    "        elif args.validate:\n",
    "            # validate\n",
    "            model = Model(loader,charList,decoderType,mustRestore=True)\n",
    "            validate(model, loader)\n",
    "    else:\n",
    "        # print accuracy\n",
    "        print(open(FilePath.accuracy).read())\n",
    "        model = Model(open(FilePath.charList).read(), decoderType, mustRestore=True, dump=args.dump)\n",
    "        recognize(model,FilePath.input)\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
